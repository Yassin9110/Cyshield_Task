{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9e8d85211ffc4f93906aa5b73cf27acb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2aa161c5451547ce85fd121b5e931405","IPY_MODEL_d7a5b4c601c346f790395461aa977b2c","IPY_MODEL_45f5f2b5986b45798b77ad9666aa71fe"],"layout":"IPY_MODEL_75fc1293e1a7428fa831a1e7fd2155a4"}},"2aa161c5451547ce85fd121b5e931405":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_434ee2fe362d4354b685451e78c3410e","placeholder":"​","style":"IPY_MODEL_38f45870dbb443c7a77604875857cf28","value":"Generating pairs: 100%"}},"d7a5b4c601c346f790395461aa977b2c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c561b94bbaa496a90e1165db73717f4","max":5000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a20aaf1a179f44188274c617341bbe3c","value":5000}},"45f5f2b5986b45798b77ad9666aa71fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91cb0d25fcc54ca3bc5b969e1ddfce89","placeholder":"​","style":"IPY_MODEL_dc23e3c787904a2aaa0ecf8bcf0a28ed","value":" 5000/5000 [00:00&lt;00:00, 101730.90it/s]"}},"75fc1293e1a7428fa831a1e7fd2155a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"434ee2fe362d4354b685451e78c3410e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38f45870dbb443c7a77604875857cf28":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c561b94bbaa496a90e1165db73717f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a20aaf1a179f44188274c617341bbe3c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"91cb0d25fcc54ca3bc5b969e1ddfce89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc23e3c787904a2aaa0ecf8bcf0a28ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a43845be070140e180370516b2a4e817":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb5a082efbb247c4876d052e008a54bd","IPY_MODEL_9410161fbbf04009a78e512b6c9c3604","IPY_MODEL_de404d80730e47488ea5a3d95e1f91f9"],"layout":"IPY_MODEL_f6010c3ced2143c39b81937124af0ac6"}},"eb5a082efbb247c4876d052e008a54bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_206f84e869c044439d984736156d481a","placeholder":"​","style":"IPY_MODEL_04f036516911426f884b242e50157246","value":"100%"}},"9410161fbbf04009a78e512b6c9c3604":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9e088b87f0040d8a3d3ad3d7fa553e8","max":111898327,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc097e2085bc4dc8bd7e19b3c0bb483f","value":111898327}},"de404d80730e47488ea5a3d95e1f91f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2be56e005854f5d9d11924bd8175b24","placeholder":"​","style":"IPY_MODEL_5cc5e52967cd4888b4d6a218834cbea6","value":" 107M/107M [00:01&lt;00:00, 124MB/s]"}},"f6010c3ced2143c39b81937124af0ac6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"206f84e869c044439d984736156d481a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04f036516911426f884b242e50157246":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9e088b87f0040d8a3d3ad3d7fa553e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc097e2085bc4dc8bd7e19b3c0bb483f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e2be56e005854f5d9d11924bd8175b24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cc5e52967cd4888b4d6a218834cbea6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b92d373239ee49fbb795e37c48836b15":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e4173910f6a54c3296cf56dada3fc1bd","IPY_MODEL_7a76d39a49964ffdac648411e909428a","IPY_MODEL_9290dbd9ba8249c1819ae6fe12f7b16c"],"layout":"IPY_MODEL_c4849a71dd61480bbc5e61db0d27309f"}},"e4173910f6a54c3296cf56dada3fc1bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6bcd567670b42a2b80e3ec6fffa23ee","placeholder":"​","style":"IPY_MODEL_b8ef492e3f9b492d93bf765011756b00","value":"Training:   1%"}},"7a76d39a49964ffdac648411e909428a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4ce4b369eed4611b17579c4710a6a03","max":390,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1d2faff9d8674be2a2482a61ce7ed43e","value":3}},"9290dbd9ba8249c1819ae6fe12f7b16c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f22538e255f74d86adb566b93f33d448","placeholder":"​","style":"IPY_MODEL_5b529803802c420e9a95f07e28f922f0","value":" 3/390 [00:34&lt;54:05,  8.39s/it, loss=19.3]"}},"c4849a71dd61480bbc5e61db0d27309f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6bcd567670b42a2b80e3ec6fffa23ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8ef492e3f9b492d93bf765011756b00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d4ce4b369eed4611b17579c4710a6a03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d2faff9d8674be2a2482a61ce7ed43e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f22538e255f74d86adb566b93f33d448":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b529803802c420e9a95f07e28f922f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade  torchvision facenet-pytorch","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"4mj8tH9cUPXp","outputId":"e0eef0ac-fa1d-4363-904d-fecd10273986","jupyter":{"outputs_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T01:01:44.172198Z","iopub.execute_input":"2025-09-12T01:01:44.172475Z","iopub.status.idle":"2025-09-12T01:05:03.414205Z","shell.execute_reply.started":"2025-09-12T01:01:44.172452Z","shell.execute_reply":"2025-09-12T01:05:03.413398Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nCollecting torchvision\n  Downloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\nCollecting facenet-pytorch\n  Downloading facenet_pytorch-2.6.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nCollecting torch==2.8.0 (from torchvision)\n  Downloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->torchvision) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->torchvision) (4.14.0)\nCollecting sympy>=1.13.3 (from torch==2.8.0->torchvision)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->torchvision) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->torchvision) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0->torchvision) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch==2.8.0->torchvision)\n  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-runtime-cu12==12.8.90 (from torch==2.8.0->torchvision)\n  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-cupti-cu12==12.8.90 (from torch==2.8.0->torchvision)\n  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cudnn-cu12==9.10.2.21 (from torch==2.8.0->torchvision)\n  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cublas-cu12==12.8.4.1 (from torch==2.8.0->torchvision)\n  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufft-cu12==11.3.3.83 (from torch==2.8.0->torchvision)\n  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-curand-cu12==10.3.9.90 (from torch==2.8.0->torchvision)\n  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cusolver-cu12==11.7.3.90 (from torch==2.8.0->torchvision)\n  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cusparse-cu12==12.5.8.93 (from torch==2.8.0->torchvision)\n  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cusparselt-cu12==0.7.1 (from torch==2.8.0->torchvision)\n  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\nCollecting nvidia-nccl-cu12==2.27.3 (from torch==2.8.0->torchvision)\n  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvtx-cu12==12.8.90 (from torch==2.8.0->torchvision)\n  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvjitlink-cu12==12.8.93 (from torch==2.8.0->torchvision)\n  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufile-cu12==1.13.1.3 (from torch==2.8.0->torchvision)\n  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting triton==3.4.0 (from torch==2.8.0->torchvision)\n  Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.4.0->torch==2.8.0->torchvision) (75.2.0)\nCollecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n  Downloading pillow-10.2.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\nRequirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (2.32.4)\nINFO: pip is looking at multiple versions of facenet-pytorch to determine which version is compatible with other requirements. This could take a while.\nCollecting facenet-pytorch\n  Downloading facenet_pytorch-2.5.3-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2025.6.15)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.8.0->torchvision) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.8.0->torchvision) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\nDownloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl (8.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (888.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m888.1/888.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.5/155.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading facenet_pytorch-2.5.3-py3-none-any.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m109.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, facenet-pytorch\n  Attempting uninstall: nvidia-cusparselt-cu12\n    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.1\n    Uninstalling sympy-1.13.1:\n      Successfully uninstalled sympy-1.13.1\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0+cu124\n    Uninstalling torch-2.6.0+cu124:\n      Successfully uninstalled torch-2.6.0+cu124\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.21.0+cu124\n    Uninstalling torchvision-0.21.0+cu124:\n      Successfully uninstalled torchvision-0.21.0+cu124\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.8.0 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed facenet-pytorch-2.5.3 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 sympy-1.14.0 torch-2.8.0 torchvision-0.23.0 triton-3.4.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport shutil\nimport pandas as pd\n\n# Paths\ncsv_path = \"/kaggle/input/cacd-filtered-dataset/CACD_features_sex.csv\"\nimages_root = \"/kaggle/input/cacd-filtered-dataset/cacd_split/cacd_split\"\noutput_root = \"/kaggle/working/cacd_filtered_top200\"\noutput_csv_path = \"/kaggle/working/CACD_features_top200.csv\"\n\n# Create output directory\nos.makedirs(output_root, exist_ok=True)\n\n# Load CSV\ndf = pd.read_csv(csv_path)\n\n# Extract person folder name from image filename (e.g., \"AaronAshmore\" from \"25_Aaron_Ashmore_0005.jpg\")\ndf[\"person\"] = df[\"name\"].apply(lambda x: \"_\".join(x.split(\"_\")[1:-1]).replace(\"_\", \"\"))\n\n# Step 1: Compute age variation per person\nage_variation = df.groupby(\"person\")[\"age\"].agg(lambda x: x.max() - x.min())\n\n# Step 2: Select top 1000 persons with largest age variation\ntop_persons = age_variation.sort_values(ascending=False).head(200).index\n\n# Step 3: Filter dataframe\nfiltered_df = df[df[\"person\"].isin(top_persons)].copy()\n\n# Step 4: Copy images into new folder structure\nfor _, row in filtered_df.iterrows():\n    person = row[\"person\"]\n    img_name = row[\"name\"]  # e.g., \"25_Aaron_Ashmore_0005.jpg\"\n    \n    src = os.path.join(images_root, person, img_name)\n    dst_dir = os.path.join(output_root, person)\n    dst = os.path.join(dst_dir, img_name)\n    \n    os.makedirs(dst_dir, exist_ok=True)\n    \n    if os.path.exists(src):\n        shutil.copy(src, dst)\n\n# Step 5: Save new CSV\nfiltered_df.to_csv(output_csv_path, index=False)\n\nprint(f\"✅ Done! Filtered dataset saved at: {output_root}\")\nprint(f\"CSV saved at: {output_csv_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T01:05:08.583589Z","iopub.execute_input":"2025-09-12T01:05:08.584206Z","iopub.status.idle":"2025-09-12T01:07:37.978934Z","shell.execute_reply.started":"2025-09-12T01:05:08.584171Z","shell.execute_reply":"2025-09-12T01:07:37.978293Z"}},"outputs":[{"name":"stdout","text":"✅ Done! Filtered dataset saved at: /kaggle/working/cacd_filtered_top200\nCSV saved at: /kaggle/working/CACD_features_top200.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nfrom glob import glob\nfrom PIL import Image\nimport torch\nfrom facenet_pytorch import MTCNN\nfrom tqdm import tqdm\n\n# --- Configuration ---\n# 1. Set the path to your root folder containing the identity subfolders.\nSOURCE_DATA_DIR = \"/kaggle/working/cacd_filtered_top200/\"\n\n# 2. Set the path where the processed (cropped and aligned) faces will be saved.\nPROCESSED_DATA_DIR = \"/kaggle/working/processed_aifr_faces/\"\n\n# 3. MTCNN parameters\n# The size of the output image. ArcFace models are often trained on 112x112 or 160x160.\n# Let's use 160x160, which is standard for FaceNet-based models.\nIMAGE_SIZE = 160\n# Margin adds padding around the detected face bounding box.\nMARGIN = 20\n\n# --- GPU/CPU Device Setup ---\n# Automatically select a GPU if available, otherwise fall back to CPU.\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint(f'Running on device: {device}')\n\n# --- Instantiate MTCNN ---\n# keep_all=False ensures that we only get the most confident face detection if multiple faces are in the image.\n# post_process=True normalizes the output tensor image to the range [-1, 1], which is standard for many models.\nmtcnn = MTCNN(\n    image_size=IMAGE_SIZE,\n    margin=MARGIN,\n    keep_all=False,\n    post_process=True,\n    device=device\n)\n\n# --- Main Processing Loop ---\ndef process_and_save_faces():\n    \"\"\"\n    Finds all images in the source directory, detects faces, aligns them,\n    and saves them to the processed directory, maintaining the folder structure.\n    \"\"\"\n    print(\"Starting face detection and alignment process...\")\n\n    # Use os.walk to recursively go through the directory structure\n    for dirpath, _, filenames in os.walk(SOURCE_DATA_DIR):\n        # Filter for image files\n        image_paths = [os.path.join(dirpath, f) for f in filenames if f.endswith(('.jpg', '.jpeg', '.png'))]\n\n        if not image_paths:\n            continue\n\n        # Create the corresponding subfolder in the destination directory\n        relative_path = os.path.relpath(dirpath, SOURCE_DATA_DIR)\n        dest_folder = os.path.join(PROCESSED_DATA_DIR, relative_path)\n        os.makedirs(dest_folder, exist_ok=True)\n\n        print(f\"Processing folder: {relative_path}\")\n\n        # Use tqdm for a progress bar\n        for image_path in tqdm(image_paths, desc=f\"  -> {relative_path}\"):\n            try:\n                # Open the image\n                img = Image.open(image_path).convert('RGB')\n\n                # Use MTCNN to detect and align the face\n                face_tensor = mtcnn(img)\n\n                # Check if a face was detected\n                if face_tensor is not None:\n                    # Construct the output path\n                    filename = os.path.basename(image_path)\n                    output_path = os.path.join(dest_folder, filename)\n\n                    # Convert tensor to a savable image format\n                    # The tensor is [-1, 1], so we need to scale it to [0, 255]\n                    face_tensor = (face_tensor + 1) / 2.0\n                    # Use torchvision's utility to save the tensor as an image\n                    from torchvision.utils import save_image\n                    save_image(face_tensor, output_path)\n\n                else:\n                    # If no face is detected, print a warning\n                    print(f\"\\n[WARNING] No face detected in: {image_path}. Skipping.\")\n\n            except Exception as e:\n                # Catch potential errors like corrupted image files\n                print(f\"\\n[ERROR] Could not process {image_path}. Reason: {e}. Skipping.\")\n\n    print(\"\\nProcessing complete!\")\n    print(f\"All aligned faces are saved in: {PROCESSED_DATA_DIR}\")\n\n\n\nprocess_and_save_faces()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"m8eGMhhlg4h1","outputId":"cbc5d31d-9641-4f9e-a114-ed234517add7","jupyter":{"outputs_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T01:07:44.808519Z","iopub.execute_input":"2025-09-12T01:07:44.808763Z","iopub.status.idle":"2025-09-12T01:15:21.596915Z","shell.execute_reply.started":"2025-09-12T01:07:44.808745Z","shell.execute_reply":"2025-09-12T01:15:21.596129Z"}},"outputs":[{"name":"stdout","text":"Running on device: cuda:0\nStarting face detection and alignment process...\nProcessing folder: AmberTamblyn\n","output_type":"stream"},{"name":"stderr","text":"  -> AmberTamblyn: 100%|██████████| 100/100 [00:03<00:00, 26.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AbbieCornish\n","output_type":"stream"},{"name":"stderr","text":"  -> AbbieCornish: 100%|██████████| 108/108 [00:03<00:00, 34.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AllySheedy\n","output_type":"stream"},{"name":"stderr","text":"  -> AllySheedy:  44%|████▍     | 32/72 [00:01<00:01, 32.06it/s]","output_type":"stream"},{"name":"stdout","text":"\n[WARNING] No face detected in: /kaggle/working/cacd_filtered_top200/AllySheedy/45_Ally_Sheedy_0005.jpg. Skipping.\n","output_type":"stream"},{"name":"stderr","text":"  -> AllySheedy: 100%|██████████| 72/72 [00:02<00:00, 32.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AliceEve\n","output_type":"stream"},{"name":"stderr","text":"  -> AliceEve: 100%|██████████| 80/80 [00:02<00:00, 36.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AryeGross\n","output_type":"stream"},{"name":"stderr","text":"  -> AryeGross: 100%|██████████| 38/38 [00:01<00:00, 34.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BobSaget\n","output_type":"stream"},{"name":"stderr","text":"  -> BobSaget: 100%|██████████| 85/85 [00:02<00:00, 35.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AlfredMolina\n","output_type":"stream"},{"name":"stderr","text":"  -> AlfredMolina: 100%|██████████| 80/80 [00:02<00:00, 34.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AnniePotts\n","output_type":"stream"},{"name":"stderr","text":"  -> AnniePotts: 100%|██████████| 69/69 [00:02<00:00, 31.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AndrewMcCarthy\n","output_type":"stream"},{"name":"stderr","text":"  -> AndrewMcCarthy: 100%|██████████| 92/92 [00:02<00:00, 36.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AnnaFaris\n","output_type":"stream"},{"name":"stderr","text":"  -> AnnaFaris: 100%|██████████| 81/81 [00:02<00:00, 36.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AnaleighTipton\n","output_type":"stream"},{"name":"stderr","text":"  -> AnaleighTipton: 100%|██████████| 59/59 [00:01<00:00, 35.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: VirginiaMadsen\n","output_type":"stream"},{"name":"stderr","text":"  -> VirginiaMadsen: 100%|██████████| 78/78 [00:02<00:00, 33.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BobbyCannavale\n","output_type":"stream"},{"name":"stderr","text":"  -> BobbyCannavale: 100%|██████████| 91/91 [00:02<00:00, 35.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: VinceGilligan\n","output_type":"stream"},{"name":"stderr","text":"  -> VinceGilligan: 100%|██████████| 79/79 [00:02<00:00, 34.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: WesleySnipes\n","output_type":"stream"},{"name":"stderr","text":"  -> WesleySnipes: 100%|██████████| 90/90 [00:02<00:00, 32.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: ArnoldVosloo\n","output_type":"stream"},{"name":"stderr","text":"  -> ArnoldVosloo: 100%|██████████| 72/72 [00:01<00:00, 36.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AaronAshmore\n","output_type":"stream"},{"name":"stderr","text":"  -> AaronAshmore: 100%|██████████| 70/70 [00:01<00:00, 35.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AnnaCamp\n","output_type":"stream"},{"name":"stderr","text":"  -> AnnaCamp: 100%|██████████| 75/75 [00:02<00:00, 36.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: VictorWebster\n","output_type":"stream"},{"name":"stderr","text":"  -> VictorWebster: 100%|██████████| 61/61 [00:01<00:00, 34.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: VincentCassel\n","output_type":"stream"},{"name":"stderr","text":"  -> VincentCassel: 100%|██████████| 64/64 [00:01<00:00, 34.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: WesAnderson\n","output_type":"stream"},{"name":"stderr","text":"  -> WesAnderson: 100%|██████████| 81/81 [00:02<00:00, 35.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BenStiller\n","output_type":"stream"},{"name":"stderr","text":"  -> BenStiller: 100%|██████████| 100/100 [00:02<00:00, 35.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AnnaTorv\n","output_type":"stream"},{"name":"stderr","text":"  -> AnnaTorv: 100%|██████████| 91/91 [00:02<00:00, 36.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: VickiLewis\n","output_type":"stream"},{"name":"stderr","text":"  -> VickiLewis: 100%|██████████| 37/37 [00:01<00:00, 34.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AneurinBarnard\n","output_type":"stream"},{"name":"stderr","text":"  -> AneurinBarnard: 100%|██████████| 74/74 [00:02<00:00, 34.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AliciaWitt\n","output_type":"stream"},{"name":"stderr","text":"  -> AliciaWitt: 100%|██████████| 78/78 [00:02<00:00, 33.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: WarrenKole\n","output_type":"stream"},{"name":"stderr","text":"  -> WarrenKole: 100%|██████████| 53/53 [00:01<00:00, 36.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BenAffleck\n","output_type":"stream"},{"name":"stderr","text":"  -> BenAffleck: 100%|██████████| 107/107 [00:03<00:00, 35.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AndreaRiseborough\n","output_type":"stream"},{"name":"stderr","text":"  -> AndreaRiseborough: 100%|██████████| 76/76 [00:02<00:00, 35.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AlfreWoodard\n","output_type":"stream"},{"name":"stderr","text":"  -> AlfreWoodard: 100%|██████████| 79/79 [00:02<00:00, 29.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BenWhishaw\n","output_type":"stream"},{"name":"stderr","text":"  -> BenWhishaw: 100%|██████████| 95/95 [00:02<00:00, 33.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AmandaCrew\n","output_type":"stream"},{"name":"stderr","text":"  -> AmandaCrew: 100%|██████████| 68/68 [00:01<00:00, 35.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AasifMandvi\n","output_type":"stream"},{"name":"stderr","text":"  -> AasifMandvi: 100%|██████████| 75/75 [00:02<00:00, 36.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AnneHeche\n","output_type":"stream"},{"name":"stderr","text":"  -> AnneHeche: 100%|██████████| 84/84 [00:02<00:00, 36.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AliaShawkat\n","output_type":"stream"},{"name":"stderr","text":"  -> AliaShawkat: 100%|██████████| 71/71 [00:02<00:00, 34.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AriGraynor\n","output_type":"stream"},{"name":"stderr","text":"  -> AriGraynor: 100%|██████████| 80/80 [00:02<00:00, 36.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BillMumy\n","output_type":"stream"},{"name":"stderr","text":"  -> BillMumy: 100%|██████████| 50/50 [00:01<00:00, 32.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: WendiMcLendon-Covey\n","output_type":"stream"},{"name":"stderr","text":"  -> WendiMcLendon-Covey: 100%|██████████| 52/52 [00:01<00:00, 37.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AudreyTautou\n","output_type":"stream"},{"name":"stderr","text":"  -> AudreyTautou: 100%|██████████| 112/112 [00:03<00:00, 34.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: VingRhames\n","output_type":"stream"},{"name":"stderr","text":"  -> VingRhames: 100%|██████████| 59/59 [00:01<00:00, 32.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: WendyMakkena\n","output_type":"stream"},{"name":"stderr","text":"  -> WendyMakkena: 100%|██████████| 37/37 [00:01<00:00, 33.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AdamArkin\n","output_type":"stream"},{"name":"stderr","text":"  -> AdamArkin: 100%|██████████| 65/65 [00:01<00:00, 36.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AmandaSeyfried\n","output_type":"stream"},{"name":"stderr","text":"  -> AmandaSeyfried: 100%|██████████| 114/114 [00:03<00:00, 36.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BillPaxton\n","output_type":"stream"},{"name":"stderr","text":"  -> BillPaxton: 100%|██████████| 75/75 [00:02<00:00, 36.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: WillArnett\n","output_type":"stream"},{"name":"stderr","text":"  -> WillArnett: 100%|██████████| 80/80 [00:02<00:00, 36.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: ArlissHoward\n","output_type":"stream"},{"name":"stderr","text":"  -> ArlissHoward: 100%|██████████| 37/37 [00:01<00:00, 35.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AndreBraugher\n","output_type":"stream"},{"name":"stderr","text":"  -> AndreBraugher: 100%|██████████| 61/61 [00:01<00:00, 31.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: VanessaLachey\n","output_type":"stream"},{"name":"stderr","text":"  -> VanessaLachey: 100%|██████████| 74/74 [00:02<00:00, 35.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: WayneKnight\n","output_type":"stream"},{"name":"stderr","text":"  -> WayneKnight: 100%|██████████| 65/65 [00:01<00:00, 35.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AmandaBynes\n","output_type":"stream"},{"name":"stderr","text":"  -> AmandaBynes: 100%|██████████| 110/110 [00:03<00:00, 35.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AndrewDivoff\n","output_type":"stream"},{"name":"stderr","text":"  -> AndrewDivoff: 100%|██████████| 45/45 [00:01<00:00, 33.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AmyJoJohnson\n","output_type":"stream"},{"name":"stderr","text":"  -> AmyJoJohnson: 100%|██████████| 57/57 [00:01<00:00, 32.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: WendyCrewson\n","output_type":"stream"},{"name":"stderr","text":"  -> WendyCrewson: 100%|██████████| 58/58 [00:01<00:00, 34.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: WhoopiGoldberg\n","output_type":"stream"},{"name":"stderr","text":"  -> WhoopiGoldberg: 100%|██████████| 84/84 [00:02<00:00, 29.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: WarwickDavis\n","output_type":"stream"},{"name":"stderr","text":"  -> WarwickDavis: 100%|██████████| 72/72 [00:01<00:00, 36.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AnnabethGish\n","output_type":"stream"},{"name":"stderr","text":"  -> AnnabethGish: 100%|██████████| 73/73 [00:02<00:00, 34.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: 50Cent\n","output_type":"stream"},{"name":"stderr","text":"  -> 50Cent: 100%|██████████| 78/78 [00:02<00:00, 30.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AaronTveit\n","output_type":"stream"},{"name":"stderr","text":"  -> AaronTveit: 100%|██████████| 80/80 [00:02<00:00, 35.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AngelaCartwright\n","output_type":"stream"},{"name":"stderr","text":"  -> AngelaCartwright: 100%|██████████| 51/51 [00:01<00:00, 33.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AmandaPlummer\n","output_type":"stream"},{"name":"stderr","text":"  -> AmandaPlummer: 100%|██████████| 62/62 [00:01<00:00, 34.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AndrewGarfield\n","output_type":"stream"},{"name":"stderr","text":"  -> AndrewGarfield: 100%|██████████| 104/104 [00:03<00:00, 33.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: VeraFarmiga\n","output_type":"stream"},{"name":"stderr","text":"  -> VeraFarmiga: 100%|██████████| 65/65 [00:01<00:00, 33.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BarbaraNiven\n","output_type":"stream"},{"name":"stderr","text":"  -> BarbaraNiven: 100%|██████████| 51/51 [00:01<00:00, 36.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[WARNING] No face detected in: /kaggle/working/cacd_filtered_top200/BarbaraNiven/59_Barbara_Niven_0002.jpg. Skipping.\nProcessing folder: AnjelicaHuston\n","output_type":"stream"},{"name":"stderr","text":"  -> AnjelicaHuston: 100%|██████████| 76/76 [00:02<00:00, 34.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AshleyOlsen\n","output_type":"stream"},{"name":"stderr","text":"  -> AshleyOlsen:  95%|█████████▌| 100/105 [00:02<00:00, 35.50it/s]","output_type":"stream"},{"name":"stdout","text":"\n[WARNING] No face detected in: /kaggle/working/cacd_filtered_top200/AshleyOlsen/26_Ashley_Olsen_0007.jpg. Skipping.\n","output_type":"stream"},{"name":"stderr","text":"  -> AshleyOlsen: 100%|██████████| 105/105 [00:02<00:00, 36.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AnnieGolden\n","output_type":"stream"},{"name":"stderr","text":"  -> AnnieGolden: 100%|██████████| 62/62 [00:01<00:00, 32.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BillyCampbell\n","output_type":"stream"},{"name":"stderr","text":"  -> BillyCampbell: 100%|██████████| 76/76 [00:02<00:00, 34.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AmberValletta\n","output_type":"stream"},{"name":"stderr","text":"  -> AmberValletta: 100%|██████████| 74/74 [00:02<00:00, 35.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AmyPoehler\n","output_type":"stream"},{"name":"stderr","text":"  -> AmyPoehler: 100%|██████████| 96/96 [00:02<00:00, 36.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AmberHeard\n","output_type":"stream"},{"name":"stderr","text":"  -> AmberHeard: 100%|██████████| 94/94 [00:02<00:00, 35.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AnthonyEdwards\n","output_type":"stream"},{"name":"stderr","text":"  -> AnthonyEdwards: 100%|██████████| 73/73 [00:02<00:00, 35.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AlexisKnapp\n","output_type":"stream"},{"name":"stderr","text":"  -> AlexisKnapp: 100%|██████████| 58/58 [00:01<00:00, 35.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BillyBobThornton\n","output_type":"stream"},{"name":"stderr","text":"  -> BillyBobThornton: 100%|██████████| 82/82 [00:02<00:00, 35.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AvrilLavigne\n","output_type":"stream"},{"name":"stderr","text":"  -> AvrilLavigne: 100%|██████████| 97/97 [00:02<00:00, 38.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AnnetteOToole\n","output_type":"stream"},{"name":"stderr","text":"  -> AnnetteOToole: 100%|██████████| 57/57 [00:01<00:00, 34.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BilliePiper\n","output_type":"stream"},{"name":"stderr","text":"  -> BilliePiper: 100%|██████████| 88/88 [00:02<00:00, 35.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AmandaSetton\n","output_type":"stream"},{"name":"stderr","text":"  -> AmandaSetton: 100%|██████████| 38/38 [00:01<00:00, 33.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AbbyElliott\n","output_type":"stream"},{"name":"stderr","text":"  -> AbbyElliott: 100%|██████████| 68/68 [00:01<00:00, 34.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BillyCrudup\n","output_type":"stream"},{"name":"stderr","text":"  -> BillyCrudup: 100%|██████████| 80/80 [00:02<00:00, 35.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: ArmieHammer\n","output_type":"stream"},{"name":"stderr","text":"  -> ArmieHammer: 100%|██████████| 115/115 [00:03<00:00, 35.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BarryPepper\n","output_type":"stream"},{"name":"stderr","text":"  -> BarryPepper: 100%|██████████| 69/69 [00:01<00:00, 36.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AliceKrige\n","output_type":"stream"},{"name":"stderr","text":"  -> AliceKrige: 100%|██████████| 64/64 [00:01<00:00, 33.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AlyssaMilano\n","output_type":"stream"},{"name":"stderr","text":"  -> AlyssaMilano: 100%|██████████| 108/108 [00:03<00:00, 35.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AllisonWilliams\n","output_type":"stream"},{"name":"stderr","text":"  -> AllisonWilliams: 100%|██████████| 90/90 [00:02<00:00, 35.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AdamGoldberg\n","output_type":"stream"},{"name":"stderr","text":"  -> AdamGoldberg: 100%|██████████| 61/61 [00:01<00:00, 33.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AmyAdams\n","output_type":"stream"},{"name":"stderr","text":"  -> AmyAdams: 100%|██████████| 114/114 [00:03<00:00, 35.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: ViolaDavis\n","output_type":"stream"},{"name":"stderr","text":"  -> ViolaDavis: 100%|██████████| 84/84 [00:02<00:00, 31.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BobOdenkirk\n","output_type":"stream"},{"name":"stderr","text":"  -> BobOdenkirk: 100%|██████████| 50/50 [00:01<00:00, 37.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BoDerek\n","output_type":"stream"},{"name":"stderr","text":"  -> BoDerek: 100%|██████████| 70/70 [00:01<00:00, 36.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AngLee\n","output_type":"stream"},{"name":"stderr","text":"  -> AngLee: 100%|██████████| 82/82 [00:02<00:00, 36.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BazLuhrmann\n","output_type":"stream"},{"name":"stderr","text":"  -> BazLuhrmann: 100%|██████████| 83/83 [00:02<00:00, 36.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AlyMichalka\n","output_type":"stream"},{"name":"stderr","text":"  -> AlyMichalka:  24%|██▍       | 20/83 [00:00<00:01, 35.38it/s]","output_type":"stream"},{"name":"stdout","text":"\n[WARNING] No face detected in: /kaggle/working/cacd_filtered_top200/AlyMichalka/23_Aly_Michalka_0008.jpg. Skipping.\n","output_type":"stream"},{"name":"stderr","text":"  -> AlyMichalka:  48%|████▊     | 40/83 [00:01<00:01, 34.51it/s]","output_type":"stream"},{"name":"stdout","text":"\n[WARNING] No face detected in: /kaggle/working/cacd_filtered_top200/AlyMichalka/23_Aly_Michalka_0017.jpg. Skipping.\n","output_type":"stream"},{"name":"stderr","text":"  -> AlyMichalka: 100%|██████████| 83/83 [00:02<00:00, 35.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AntonYelchin\n","output_type":"stream"},{"name":"stderr","text":"  -> AntonYelchin: 100%|██████████| 84/84 [00:02<00:00, 33.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AshtonKutcher\n","output_type":"stream"},{"name":"stderr","text":"  -> AshtonKutcher: 100%|██████████| 100/100 [00:02<00:00, 33.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: VinnieJones\n","output_type":"stream"},{"name":"stderr","text":"  -> VinnieJones: 100%|██████████| 79/79 [00:02<00:00, 35.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BiancaKajlich\n","output_type":"stream"},{"name":"stderr","text":"  -> BiancaKajlich: 100%|██████████| 67/67 [00:01<00:00, 35.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: VinessaShaw\n","output_type":"stream"},{"name":"stderr","text":"  -> VinessaShaw: 100%|██████████| 56/56 [00:01<00:00, 35.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BeauMirchoff\n","output_type":"stream"},{"name":"stderr","text":"  -> BeauMirchoff: 100%|██████████| 59/59 [00:01<00:00, 34.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: VivicaA.Fox\n","output_type":"stream"},{"name":"stderr","text":"  -> VivicaA.Fox: 100%|██████████| 82/82 [00:02<00:00, 32.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AmandaTapping\n","output_type":"stream"},{"name":"stderr","text":"  -> AmandaTapping: 100%|██████████| 98/98 [00:02<00:00, 34.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AaronJohnson\n","output_type":"stream"},{"name":"stderr","text":"  -> AaronJohnson: 100%|██████████| 71/71 [00:02<00:00, 33.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: VladimirKulich\n","output_type":"stream"},{"name":"stderr","text":"  -> VladimirKulich: 100%|██████████| 40/40 [00:01<00:00, 32.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AndySamberg\n","output_type":"stream"},{"name":"stderr","text":"  -> AndySamberg: 100%|██████████| 104/104 [00:03<00:00, 31.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AmandaBearse\n","output_type":"stream"},{"name":"stderr","text":"  -> AmandaBearse: 100%|██████████| 49/49 [00:01<00:00, 34.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AnsonMount\n","output_type":"stream"},{"name":"stderr","text":"  -> AnsonMount: 100%|██████████| 43/43 [00:01<00:00, 34.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: ArsenioHall\n","output_type":"stream"},{"name":"stderr","text":"  -> ArsenioHall:   6%|▋         | 4/62 [00:00<00:01, 34.07it/s]","output_type":"stream"},{"name":"stdout","text":"\n[WARNING] No face detected in: /kaggle/working/cacd_filtered_top200/ArsenioHall/55_Arsenio_Hall_0009.jpg. Skipping.\n","output_type":"stream"},{"name":"stderr","text":"  -> ArsenioHall: 100%|██████████| 62/62 [00:01<00:00, 31.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BillCondon\n","output_type":"stream"},{"name":"stderr","text":"  -> BillCondon: 100%|██████████| 74/74 [00:02<00:00, 33.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: WendySchaal\n","output_type":"stream"},{"name":"stderr","text":"  -> WendySchaal: 100%|██████████| 62/62 [00:01<00:00, 35.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AmericaFerrera\n","output_type":"stream"},{"name":"stderr","text":"  -> AmericaFerrera: 100%|██████████| 103/103 [00:02<00:00, 34.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BillyRayCyrus\n","output_type":"stream"},{"name":"stderr","text":"  -> BillyRayCyrus: 100%|██████████| 84/84 [00:02<00:00, 34.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AmyYasbeck\n","output_type":"stream"},{"name":"stderr","text":"  -> AmyYasbeck: 100%|██████████| 60/60 [00:01<00:00, 34.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BenFoster\n","output_type":"stream"},{"name":"stderr","text":"  -> BenFoster:   5%|▌         | 4/79 [00:00<00:01, 38.93it/s]","output_type":"stream"},{"name":"stdout","text":"\n[WARNING] No face detected in: /kaggle/working/cacd_filtered_top200/BenFoster/27_Ben_Foster_0003.jpg. Skipping.\n","output_type":"stream"},{"name":"stderr","text":"  -> BenFoster: 100%|██████████| 79/79 [00:02<00:00, 35.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BenedictCumberbatch\n","output_type":"stream"},{"name":"stderr","text":"  -> BenedictCumberbatch: 100%|██████████| 79/79 [00:02<00:00, 34.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AnthonyHead\n","output_type":"stream"},{"name":"stderr","text":"  -> AnthonyHead: 100%|██████████| 87/87 [00:02<00:00, 35.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AlfonsoCuarón\n","output_type":"stream"},{"name":"stderr","text":"  -> AlfonsoCuarón: 100%|██████████| 53/53 [00:01<00:00, 33.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AndySerkis\n","output_type":"stream"},{"name":"stderr","text":"  -> AndySerkis: 100%|██████████| 81/81 [00:02<00:00, 33.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AnnetteBening\n","output_type":"stream"},{"name":"stderr","text":"  -> AnnetteBening: 100%|██████████| 96/96 [00:02<00:00, 34.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AlisonPill\n","output_type":"stream"},{"name":"stderr","text":"  -> AlisonPill: 100%|██████████| 73/73 [00:02<00:00, 36.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AmyIrving\n","output_type":"stream"},{"name":"stderr","text":"  -> AmyIrving: 100%|██████████| 56/56 [00:01<00:00, 30.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BonnieHunt\n","output_type":"stream"},{"name":"stderr","text":"  -> BonnieHunt: 100%|██████████| 75/75 [00:02<00:00, 36.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AmySedaris\n","output_type":"stream"},{"name":"stderr","text":"  -> AmySedaris:  45%|████▌     | 36/80 [00:01<00:01, 33.02it/s]","output_type":"stream"},{"name":"stdout","text":"\n[WARNING] No face detected in: /kaggle/working/cacd_filtered_top200/AmySedaris/45_Amy_Sedaris_0014.jpg. Skipping.\n","output_type":"stream"},{"name":"stderr","text":"  -> AmySedaris: 100%|██████████| 80/80 [00:02<00:00, 34.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: ArielleKebbel\n","output_type":"stream"},{"name":"stderr","text":"  -> ArielleKebbel: 100%|██████████| 75/75 [00:02<00:00, 35.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AmandaRighetti\n","output_type":"stream"},{"name":"stderr","text":"  -> AmandaRighetti: 100%|██████████| 81/81 [00:02<00:00, 34.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BellamyYoung\n","output_type":"stream"},{"name":"stderr","text":"  -> BellamyYoung: 100%|██████████| 42/42 [00:01<00:00, 35.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AshleyBenson\n","output_type":"stream"},{"name":"stderr","text":"  -> AshleyBenson: 100%|██████████| 91/91 [00:02<00:00, 36.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AntonioBanderas\n","output_type":"stream"},{"name":"stderr","text":"  -> AntonioBanderas: 100%|██████████| 75/75 [00:02<00:00, 34.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AshleyWilliams\n","output_type":"stream"},{"name":"stderr","text":"  -> AshleyWilliams: 100%|██████████| 77/77 [00:02<00:00, 36.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AliLarter\n","output_type":"stream"},{"name":"stderr","text":"  -> AliLarter: 100%|██████████| 96/96 [00:02<00:00, 36.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BenBarnes\n","output_type":"stream"},{"name":"stderr","text":"  -> BenBarnes: 100%|██████████| 109/109 [00:03<00:00, 35.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AaronSorkin\n","output_type":"stream"},{"name":"stderr","text":"  -> AaronSorkin: 100%|██████████| 97/97 [00:02<00:00, 34.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AlexisDenisof\n","output_type":"stream"},{"name":"stderr","text":"  -> AlexisDenisof: 100%|██████████| 73/73 [00:02<00:00, 34.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AllisonJanney\n","output_type":"stream"},{"name":"stderr","text":"  -> AllisonJanney: 100%|██████████| 71/71 [00:02<00:00, 33.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AnnabellaSciorra\n","output_type":"stream"},{"name":"stderr","text":"  -> AnnabellaSciorra: 100%|██████████| 68/68 [00:02<00:00, 33.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AllisonScagliotti\n","output_type":"stream"},{"name":"stderr","text":"  -> AllisonScagliotti: 100%|██████████| 66/66 [00:01<00:00, 34.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AndrewDiceClay\n","output_type":"stream"},{"name":"stderr","text":"  -> AndrewDiceClay: 100%|██████████| 44/44 [00:01<00:00, 35.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BillyZane\n","output_type":"stream"},{"name":"stderr","text":"  -> BillyZane: 100%|██████████| 78/78 [00:02<00:00, 36.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: Anne-MarieDuff\n","output_type":"stream"},{"name":"stderr","text":"  -> Anne-MarieDuff: 100%|██████████| 57/57 [00:01<00:00, 34.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AnthonyMichaelHall\n","output_type":"stream"},{"name":"stderr","text":"  -> AnthonyMichaelHall: 100%|██████████| 73/73 [00:02<00:00, 36.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AnneHathaway\n","output_type":"stream"},{"name":"stderr","text":"  -> AnneHathaway: 100%|██████████| 121/121 [00:03<00:00, 34.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BillPullman\n","output_type":"stream"},{"name":"stderr","text":"  -> BillPullman: 100%|██████████| 81/81 [00:02<00:00, 36.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AngieHarmon\n","output_type":"stream"},{"name":"stderr","text":"  -> AngieHarmon: 100%|██████████| 90/90 [00:02<00:00, 35.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AprilBowlby\n","output_type":"stream"},{"name":"stderr","text":"  -> AprilBowlby: 100%|██████████| 71/71 [00:02<00:00, 33.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AdamBaldwin\n","output_type":"stream"},{"name":"stderr","text":"  -> AdamBaldwin: 100%|██████████| 80/80 [00:02<00:00, 35.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: A.J.Cook\n","output_type":"stream"},{"name":"stderr","text":"  -> A.J.Cook: 100%|██████████| 75/75 [00:01<00:00, 38.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BobcatGoldthwait\n","output_type":"stream"},{"name":"stderr","text":"  -> BobcatGoldthwait: 100%|██████████| 57/57 [00:01<00:00, 33.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AlonaTal\n","output_type":"stream"},{"name":"stderr","text":"  -> AlonaTal: 100%|██████████| 96/96 [00:02<00:00, 36.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BillMoseley\n","output_type":"stream"},{"name":"stderr","text":"  -> BillMoseley: 100%|██████████| 69/69 [00:01<00:00, 35.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AngelaBassett\n","output_type":"stream"},{"name":"stderr","text":"  -> AngelaBassett: 100%|██████████| 95/95 [00:02<00:00, 32.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BebeNeuwirth\n","output_type":"stream"},{"name":"stderr","text":"  -> BebeNeuwirth: 100%|██████████| 72/72 [00:02<00:00, 34.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: WilWheaton\n","output_type":"stream"},{"name":"stderr","text":"  -> WilWheaton: 100%|██████████| 87/87 [00:02<00:00, 34.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BeckiNewton\n","output_type":"stream"},{"name":"stderr","text":"  -> BeckiNewton: 100%|██████████| 102/102 [00:02<00:00, 35.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AshleyJohnson\n","output_type":"stream"},{"name":"stderr","text":"  -> AshleyJohnson: 100%|██████████| 76/76 [00:02<00:00, 35.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AnnaLynneMcCord\n","output_type":"stream"},{"name":"stderr","text":"  -> AnnaLynneMcCord:  20%|█▉        | 24/121 [00:00<00:02, 32.91it/s]","output_type":"stream"},{"name":"stdout","text":"\n[WARNING] No face detected in: /kaggle/working/cacd_filtered_top200/AnnaLynneMcCord/25_AnnaLynne_McCord_0007.jpg. Skipping.\n","output_type":"stream"},{"name":"stderr","text":"  -> AnnaLynneMcCord: 100%|██████████| 121/121 [00:03<00:00, 33.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AlysonHannigan\n","output_type":"stream"},{"name":"stderr","text":"  -> AlysonHannigan: 100%|██████████| 95/95 [00:02<00:00, 34.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AmandaPeet\n","output_type":"stream"},{"name":"stderr","text":"  -> AmandaPeet: 100%|██████████| 96/96 [00:02<00:00, 34.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AaronEckhart\n","output_type":"stream"},{"name":"stderr","text":"  -> AaronEckhart: 100%|██████████| 87/87 [00:02<00:00, 36.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AnnaKendrick\n","output_type":"stream"},{"name":"stderr","text":"  -> AnnaKendrick: 100%|██████████| 105/105 [00:03<00:00, 34.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AliCobrin\n","output_type":"stream"},{"name":"stderr","text":"  -> AliCobrin: 100%|██████████| 60/60 [00:01<00:00, 34.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AmyAcker\n","output_type":"stream"},{"name":"stderr","text":"  -> AmyAcker: 100%|██████████| 87/87 [00:02<00:00, 32.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AnnaGunn\n","output_type":"stream"},{"name":"stderr","text":"  -> AnnaGunn: 100%|██████████| 71/71 [00:01<00:00, 35.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AsiaArgento\n","output_type":"stream"},{"name":"stderr","text":"  -> AsiaArgento: 100%|██████████| 64/64 [00:01<00:00, 34.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BillyBurke\n","output_type":"stream"},{"name":"stderr","text":"  -> BillyBurke: 100%|██████████| 89/89 [00:02<00:00, 34.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BillHader\n","output_type":"stream"},{"name":"stderr","text":"  -> BillHader: 100%|██████████| 79/79 [00:02<00:00, 35.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: ViggoMortensen\n","output_type":"stream"},{"name":"stderr","text":"  -> ViggoMortensen: 100%|██████████| 91/91 [00:02<00:00, 33.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AshleeSimpson\n","output_type":"stream"},{"name":"stderr","text":"  -> AshleeSimpson: 100%|██████████| 101/101 [00:02<00:00, 36.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AlexisDziena\n","output_type":"stream"},{"name":"stderr","text":"  -> AlexisDziena: 100%|██████████| 75/75 [00:02<00:00, 34.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AshleyTisdale\n","output_type":"stream"},{"name":"stderr","text":"  -> AshleyTisdale: 100%|██████████| 109/109 [00:02<00:00, 36.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AngelinaJolie\n","output_type":"stream"},{"name":"stderr","text":"  -> AngelinaJolie: 100%|██████████| 114/114 [00:03<00:00, 35.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AnnaPaquin\n","output_type":"stream"},{"name":"stderr","text":"  -> AnnaPaquin: 100%|██████████| 117/117 [00:03<00:00, 36.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BlairUnderwood\n","output_type":"stream"},{"name":"stderr","text":"  -> BlairUnderwood: 100%|██████████| 85/85 [00:02<00:00, 33.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AnnaChlumsky\n","output_type":"stream"},{"name":"stderr","text":"  -> AnnaChlumsky: 100%|██████████| 79/79 [00:02<00:00, 34.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AndieMacDowell\n","output_type":"stream"},{"name":"stderr","text":"  -> AndieMacDowell: 100%|██████████| 78/78 [00:02<00:00, 31.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AaronPaul\n","output_type":"stream"},{"name":"stderr","text":"  -> AaronPaul: 100%|██████████| 85/85 [00:02<00:00, 36.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: ZuleikhaRobinson\n","output_type":"stream"},{"name":"stderr","text":"  -> ZuleikhaRobinson: 100%|██████████| 65/65 [00:01<00:00, 35.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AndrewLincoln\n","output_type":"stream"},{"name":"stderr","text":"  -> AndrewLincoln: 100%|██████████| 51/51 [00:01<00:00, 35.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AmySmart\n","output_type":"stream"},{"name":"stderr","text":"  -> AmySmart: 100%|██████████| 80/80 [00:02<00:00, 36.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: VanessaWilliams\n","output_type":"stream"},{"name":"stderr","text":"  -> VanessaWilliams: 100%|██████████| 102/102 [00:03<00:00, 33.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AlexisBledel\n","output_type":"stream"},{"name":"stderr","text":"  -> AlexisBledel: 100%|██████████| 104/104 [00:02<00:00, 36.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: WentworthMiller\n","output_type":"stream"},{"name":"stderr","text":"  -> WentworthMiller: 100%|██████████| 105/105 [00:02<00:00, 37.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BlakeLively\n","output_type":"stream"},{"name":"stderr","text":"  -> BlakeLively: 100%|██████████| 118/118 [00:03<00:00, 35.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: VinceVaughn\n","output_type":"stream"},{"name":"stderr","text":"  -> VinceVaughn: 100%|██████████| 91/91 [00:02<00:00, 36.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AlisonBrie\n","output_type":"stream"},{"name":"stderr","text":"  -> AlisonBrie: 100%|██████████| 85/85 [00:02<00:00, 34.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AshleyHinshaw\n","output_type":"stream"},{"name":"stderr","text":"  -> AshleyHinshaw: 100%|██████████| 63/63 [00:01<00:00, 36.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AbigailSpencer\n","output_type":"stream"},{"name":"stderr","text":"  -> AbigailSpencer: 100%|██████████| 83/83 [00:02<00:00, 34.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AshleyJudd\n","output_type":"stream"},{"name":"stderr","text":"  -> AshleyJudd: 100%|██████████| 105/105 [00:03<00:00, 34.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AshleyGreene\n","output_type":"stream"},{"name":"stderr","text":"  -> AshleyGreene: 100%|██████████| 101/101 [00:03<00:00, 32.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AzizAnsari\n","output_type":"stream"},{"name":"stderr","text":"  -> AzizAnsari: 100%|██████████| 72/72 [00:02<00:00, 33.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BaiLing\n","output_type":"stream"},{"name":"stderr","text":"  -> BaiLing:  43%|████▎     | 33/76 [00:00<00:01, 37.28it/s]","output_type":"stream"},{"name":"stdout","text":"\n[WARNING] No face detected in: /kaggle/working/cacd_filtered_top200/BaiLing/46_Bai_Ling_0004.jpg. Skipping.\n","output_type":"stream"},{"name":"stderr","text":"  -> BaiLing: 100%|██████████| 76/76 [00:02<00:00, 36.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AllyWalker\n","output_type":"stream"},{"name":"stderr","text":"  -> AllyWalker: 100%|██████████| 60/60 [00:01<00:00, 36.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AliceBraga\n","output_type":"stream"},{"name":"stderr","text":"  -> AliceBraga: 100%|██████████| 75/75 [00:02<00:00, 34.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: VincentDOnofrio\n","output_type":"stream"},{"name":"stderr","text":"  -> VincentDOnofrio: 100%|██████████| 89/89 [00:02<00:00, 35.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AnthonyMackie\n","output_type":"stream"},{"name":"stderr","text":"  -> AnthonyMackie: 100%|██████████| 76/76 [00:02<00:00, 31.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: VinDiesel\n","output_type":"stream"},{"name":"stderr","text":"  -> VinDiesel: 100%|██████████| 77/77 [00:02<00:00, 35.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AliciaVikander\n","output_type":"stream"},{"name":"stderr","text":"  -> AliciaVikander: 100%|██████████| 63/63 [00:01<00:00, 36.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AndyGarcia\n","output_type":"stream"},{"name":"stderr","text":"  -> AndyGarcia: 100%|██████████| 90/90 [00:02<00:00, 35.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AlisonLohman\n","output_type":"stream"},{"name":"stderr","text":"  -> AlisonLohman: 100%|██████████| 83/83 [00:02<00:00, 35.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AliciaSilverstone\n","output_type":"stream"},{"name":"stderr","text":"  -> AliciaSilverstone: 100%|██████████| 99/99 [00:02<00:00, 35.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: WillFerrell\n","output_type":"stream"},{"name":"stderr","text":"  -> WillFerrell: 100%|██████████| 88/88 [00:02<00:00, 35.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: AnnaPopplewell\n","output_type":"stream"},{"name":"stderr","text":"  -> AnnaPopplewell: 100%|██████████| 102/102 [00:02<00:00, 34.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing folder: BillSkarsgård\n","output_type":"stream"},{"name":"stderr","text":"  -> BillSkarsgård: 100%|██████████| 67/67 [00:01<00:00, 35.28it/s]","output_type":"stream"},{"name":"stdout","text":"\nProcessing complete!\nAll aligned faces are saved in: /kaggle/working/processed_aifr_faces/\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# --- 1.2. Import libraries ---\nimport os\nimport random\nimport shutil\nfrom collections import defaultdict\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom facenet_pytorch import InceptionResnetV1, MTCNN\nfrom tqdm.notebook import tqdm  # Use notebook-friendly tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# --- 1.3. Global Configuration ---\n\n# Set random seed for reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n# Ensure deterministic behavior for cuDNN\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Running on device: {device}\")\n\n# --- Configuration Parameters ---\n# FIXME: UPDATE THIS PATH to your folder of processed faces from Phase 1\nPROCESSED_DATA_DIR = \"/kaggle/working/processed_aifr_faces/\"\n\n# Model parameters\nEMBEDDING_DIM = 512 # Output dimension of the InceptionResnetV1\nNUM_EPOCHS = 20\nBATCH_SIZE = 32\nLEARNING_RATE = 0.001\n\n# --- Sanity Check ---\n# Check if the processed data directory exists\nif not os.path.isdir(PROCESSED_DATA_DIR):\n    print(\"=\"*50)\n    print(f\"ERROR: The directory '{PROCESSED_DATA_DIR}' was not found.\")\n    print(\"Please make sure you have run Phase 1 (pre-processing) and have set the correct path.\")\n    print(\"=\"*50)\nelse:\n    print(f\"Successfully found processed data directory: {PROCESSED_DATA_DIR}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QEGNbS_c7rMq","outputId":"270e2abe-2ddc-4fe0-a6b4-1f20f9aa35b1","trusted":true,"execution":{"iopub.status.busy":"2025-09-12T01:20:02.221517Z","iopub.execute_input":"2025-09-12T01:20:02.222001Z","iopub.status.idle":"2025-09-12T01:20:02.230898Z","shell.execute_reply.started":"2025-09-12T01:20:02.221975Z","shell.execute_reply":"2025-09-12T01:20:02.230186Z"}},"outputs":[{"name":"stdout","text":"Running on device: cuda\nSuccessfully found processed data directory: /kaggle/working/processed_aifr_faces/\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def prepare_data_splits(base_dir, test_size=0.1, val_size=0.1):\n    \"\"\"\n    Splits identities into train, validation, and test sets.\n    Ensures that no identity appears in more than one set.\n    \"\"\"\n    print(\"Preparing data splits...\")\n    all_identity_folders = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n\n    # Split identities\n    train_identities, test_identities = train_test_split(all_identity_folders, test_size=test_size, random_state=SEED)\n    relative_val_size = val_size / (1.0 - test_size)\n    train_identities, val_identities = train_test_split(train_identities, test_size=relative_val_size, random_state=SEED)\n\n    print(f\"Total identities: {len(all_identity_folders)}\")\n    print(f\"Training identities: {len(train_identities)}\")\n    print(f\"Validation identities: {len(val_identities)}\")\n    print(f\"Test identities: {len(test_identities)}\")\n\n    # Create mapping from identity name to integer label for training\n    identity_to_label = {identity: i for i, identity in enumerate(train_identities)}\n\n    def get_filepaths_and_labels(identity_list, is_training=False):\n        filepaths, labels = [], []\n        for identity in identity_list:\n            identity_path = os.path.join(base_dir, identity)\n            images = os.listdir(identity_path)\n            for img in images:\n                filepaths.append(os.path.join(identity_path, img))\n                labels.append(identity_to_label[identity] if is_training else identity)\n        return filepaths, labels\n\n    train_files, train_labels = get_filepaths_and_labels(train_identities, is_training=True)\n    val_files, val_labels = get_filepaths_and_labels(val_identities)\n    test_files, test_labels = get_filepaths_and_labels(test_identities)\n\n    num_train_classes = len(train_identities)\n    return (train_files, train_labels), (val_files, val_labels), (test_files, test_labels), num_train_classes\n\n# --- Execute the split ---\n# This will be run once and the results will be stored in variables for later cells.\n(train_files, train_labels), (val_files, val_labels), (test_files, test_labels), NUM_TRAIN_CLASSES = prepare_data_splits(PROCESSED_DATA_DIR)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VdDrb2V9oxx2","outputId":"54c6e87c-9e10-4194-f46b-17e1e002cfd5","trusted":true,"execution":{"iopub.status.busy":"2025-09-12T01:20:11.076217Z","iopub.execute_input":"2025-09-12T01:20:11.076988Z","iopub.status.idle":"2025-09-12T01:20:11.115375Z","shell.execute_reply.started":"2025-09-12T01:20:11.076953Z","shell.execute_reply":"2025-09-12T01:20:11.114691Z"}},"outputs":[{"name":"stdout","text":"Preparing data splits...\nTotal identities: 200\nTraining identities: 160\nValidation identities: 20\nTest identities: 20\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"class FaceDataset(Dataset):\n    def __init__(self, filepaths, labels, transform=None):\n        self.filepaths, self.labels, self.transform = filepaths, labels, transform\n\n    def __len__(self):\n        return len(self.filepaths)\n\n    def __getitem__(self, idx):\n        img_path = self.filepaths[idx]\n        image = Image.open(img_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        return image, self.labels[idx]\n\ndef generate_evaluation_pairs(files, labels, num_pairs=5000):\n    pairs, is_same_list = [], []\n    identity_dict = defaultdict(list)\n    for file, label in zip(files, labels):\n        identity_dict[label].append(file)\n    identities = list(identity_dict.keys())\n\n    for _ in tqdm(range(num_pairs), desc=\"Generating pairs\"):\n        choice = random.choice([True, False])\n        if choice and len(identities) > 0: # Positive pair\n            identity = random.choice([id for id, files in identity_dict.items() if len(files) >= 2])\n            img1_path, img2_path = random.sample(identity_dict[identity], 2)\n            is_same_list.append(1)\n        else: # Negative pair\n            id1, id2 = random.sample(identities, 2)\n            img1_path = random.choice(identity_dict[id1])\n            img2_path = random.choice(identity_dict[id2])\n            is_same_list.append(0)\n        pairs.append((img1_path, img2_path))\n\n    return pairs, is_same_list\n\n# --- Define Transforms ---\ntrain_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n])\neval_transform = transforms.Compose([transforms.ToTensor()])\n\n# --- Create Datasets and Dataloaders ---\ntrain_dataset = FaceDataset(train_files, train_labels, transform=train_transform)\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n\n# Generate validation pairs (this might take a moment)\nval_pairs, val_is_same = generate_evaluation_pairs(val_files, val_labels)\n\nprint(\"Datasets, transforms, and dataloaders are ready.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["9e8d85211ffc4f93906aa5b73cf27acb","2aa161c5451547ce85fd121b5e931405","d7a5b4c601c346f790395461aa977b2c","45f5f2b5986b45798b77ad9666aa71fe","75fc1293e1a7428fa831a1e7fd2155a4","434ee2fe362d4354b685451e78c3410e","38f45870dbb443c7a77604875857cf28","9c561b94bbaa496a90e1165db73717f4","a20aaf1a179f44188274c617341bbe3c","91cb0d25fcc54ca3bc5b969e1ddfce89","dc23e3c787904a2aaa0ecf8bcf0a28ed"]},"id":"7GF_i-Mu8ER7","outputId":"c0511ebd-e19c-438e-c140-bbdb25042f40","trusted":true,"execution":{"iopub.status.busy":"2025-09-12T01:20:18.108649Z","iopub.execute_input":"2025-09-12T01:20:18.108915Z","iopub.status.idle":"2025-09-12T01:20:18.152070Z","shell.execute_reply.started":"2025-09-12T01:20:18.108898Z","shell.execute_reply":"2025-09-12T01:20:18.151297Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating pairs:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36f97011671846c1b233dcbe190fe77a"}},"metadata":{}},{"name":"stdout","text":"Datasets, transforms, and dataloaders are ready.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"class ArcFaceLoss(nn.Module):\n    def __init__(self, in_features, out_features, s=30.0, m=0.50):\n        super(ArcFaceLoss, self).__init__()\n        self.in_features, self.out_features, self.s, self.m = in_features, out_features, s, m\n        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n        self.cos_m, self.sin_m = np.cos(m), np.sin(m)\n        self.th = np.cos(np.pi - m)\n        self.mm = np.sin(np.pi - m) * m\n\n    def forward(self, embedding, label):\n        cosine = F.linear(F.normalize(embedding), F.normalize(self.weight))\n        one_hot = torch.zeros_like(cosine)\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        phi = cosine * self.cos_m - torch.sqrt((1.0 - cosine.pow(2)).clamp(0, 1)) * self.sin_m\n        phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        return output * self.s\n\nclass FaceRecognitionModel(nn.Module):\n    def __init__(self, num_classes, embedding_dim=EMBEDDING_DIM, pretrained='vggface2'):\n        super(FaceRecognitionModel, self).__init__()\n        self.backbone = InceptionResnetV1(pretrained=pretrained)\n        self.arc_face = ArcFaceLoss(in_features=embedding_dim, out_features=num_classes)\n\n    def forward(self, image, label):\n        embedding = self.backbone(image)\n        return self.arc_face(embedding, label)\n\n    def get_embedding(self, image):\n        return self.backbone(image)\n\n","metadata":{"id":"WfjZk4eo78wO","trusted":true,"execution":{"iopub.status.busy":"2025-09-12T01:20:26.600300Z","iopub.execute_input":"2025-09-12T01:20:26.600610Z","iopub.status.idle":"2025-09-12T01:20:26.608996Z","shell.execute_reply.started":"2025-09-12T01:20:26.600585Z","shell.execute_reply":"2025-09-12T01:20:26.608230Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def train_one_epoch(model, dataloader, criterion, optimizer, device):\n    model.train()\n    total_loss = 0.0\n    progress_bar = tqdm(dataloader, desc=\"Training\", leave=True)\n    for images, labels in progress_bar:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        logits = model(images, labels)\n        loss = criterion(logits, labels)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        progress_bar.set_postfix(loss=loss.item())\n    return total_loss / len(dataloader)\n\ndef validate_one_epoch(model, val_pairs, val_is_same, transform, device):\n    model.eval()\n    similarities = []\n    with torch.no_grad():\n        for img1_path, img2_path in tqdm(val_pairs, desc=\"Validating\", leave=True):\n            img1 = transform(Image.open(img1_path).convert('RGB')).unsqueeze(0).to(device)\n            img2 = transform(Image.open(img2_path).convert('RGB')).unsqueeze(0).to(device)\n            emb1, emb2 = model.get_embedding(img1), model.get_embedding(img2)\n            similarities.append(F.cosine_similarity(emb1, emb2).item())\n\n    fpr, tpr, thresholds = roc_curve(val_is_same, similarities)\n    return auc(fpr, tpr)\n\nprint(\"Training and validation functions defined.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"txZNIjb48XHv","outputId":"bd04d2e8-9b29-4a6b-bb52-b05a3e3d8ce2","trusted":true,"execution":{"iopub.status.busy":"2025-09-12T01:20:31.544360Z","iopub.execute_input":"2025-09-12T01:20:31.544883Z","iopub.status.idle":"2025-09-12T01:20:31.551752Z","shell.execute_reply.started":"2025-09-12T01:20:31.544861Z","shell.execute_reply":"2025-09-12T01:20:31.550891Z"}},"outputs":[{"name":"stdout","text":"Training and validation functions defined.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# --- Initialize Model, Loss, and Optimizer ---\nmodel = FaceRecognitionModel(num_classes=NUM_TRAIN_CLASSES).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T01:20:46.518694Z","iopub.execute_input":"2025-09-12T01:20:46.519391Z","iopub.status.idle":"2025-09-12T01:20:48.790438Z","shell.execute_reply.started":"2025-09-12T01:20:46.519359Z","shell.execute_reply":"2025-09-12T01:20:48.789639Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/107M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f12dc7386ab42c6a1d31689502f408e"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T01:20:59.962489Z","iopub.execute_input":"2025-09-12T01:20:59.963199Z","iopub.status.idle":"2025-09-12T01:20:59.974370Z","shell.execute_reply.started":"2025-09-12T01:20:59.963172Z","shell.execute_reply":"2025-09-12T01:20:59.973630Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"FaceRecognitionModel(\n  (backbone): InceptionResnetV1(\n    (conv2d_1a): BasicConv2d(\n      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (conv2d_2a): BasicConv2d(\n      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (conv2d_2b): BasicConv2d(\n      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (conv2d_3b): BasicConv2d(\n      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (conv2d_4a): BasicConv2d(\n      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (conv2d_4b): BasicConv2d(\n      (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU()\n    )\n    (repeat_1): Sequential(\n      (0): Block35(\n        (branch0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (branch1): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (branch2): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (2): BasicConv2d(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n        (relu): ReLU()\n      )\n      (1): Block35(\n        (branch0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (branch1): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (branch2): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (2): BasicConv2d(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n        (relu): ReLU()\n      )\n      (2): Block35(\n        (branch0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (branch1): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (branch2): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (2): BasicConv2d(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n        (relu): ReLU()\n      )\n      (3): Block35(\n        (branch0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (branch1): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (branch2): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (2): BasicConv2d(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n        (relu): ReLU()\n      )\n      (4): Block35(\n        (branch0): BasicConv2d(\n          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (branch1): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (branch2): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (2): BasicConv2d(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n        (relu): ReLU()\n      )\n    )\n    (mixed_6a): Mixed_6a(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    )\n    (repeat_2): Sequential(\n      (0): Block17(\n        (branch0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (branch1): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (2): BasicConv2d(\n            (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n        (relu): ReLU()\n      )\n      (1): Block17(\n        (branch0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (branch1): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (2): BasicConv2d(\n            (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n        (relu): ReLU()\n      )\n      (2): Block17(\n        (branch0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (branch1): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (2): BasicConv2d(\n            (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n        (relu): ReLU()\n      )\n      (3): Block17(\n        (branch0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (branch1): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (2): BasicConv2d(\n            (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n        (relu): ReLU()\n      )\n      (4): Block17(\n        (branch0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (branch1): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (2): BasicConv2d(\n            (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n        (relu): ReLU()\n      )\n      (5): Block17(\n        (branch0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (branch1): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (2): BasicConv2d(\n            (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n        (relu): ReLU()\n      )\n      (6): Block17(\n        (branch0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (branch1): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (2): BasicConv2d(\n            (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n        (relu): ReLU()\n      )\n      (7): Block17(\n        (branch0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (branch1): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (2): BasicConv2d(\n            (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n        (relu): ReLU()\n      )\n      (8): Block17(\n        (branch0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (branch1): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (2): BasicConv2d(\n            (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n        (relu): ReLU()\n      )\n      (9): Block17(\n        (branch0): BasicConv2d(\n          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (branch1): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (2): BasicConv2d(\n            (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n        (relu): ReLU()\n      )\n    )\n    (mixed_7a): Mixed_7a(\n      (branch0): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (branch2): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    )\n    (repeat_3): Sequential(\n      (0): Block8(\n        (branch0): BasicConv2d(\n          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (branch1): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (2): BasicConv2d(\n            (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n        (relu): ReLU()\n      )\n      (1): Block8(\n        (branch0): BasicConv2d(\n          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (branch1): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (2): BasicConv2d(\n            (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n        (relu): ReLU()\n      )\n      (2): Block8(\n        (branch0): BasicConv2d(\n          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (branch1): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (2): BasicConv2d(\n            (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n        (relu): ReLU()\n      )\n      (3): Block8(\n        (branch0): BasicConv2d(\n          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (branch1): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (2): BasicConv2d(\n            (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n        (relu): ReLU()\n      )\n      (4): Block8(\n        (branch0): BasicConv2d(\n          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (branch1): Sequential(\n          (0): BasicConv2d(\n            (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (1): BasicConv2d(\n            (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n          (2): BasicConv2d(\n            (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n            (relu): ReLU()\n          )\n        )\n        (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n        (relu): ReLU()\n      )\n    )\n    (block8): Block8(\n      (branch0): BasicConv2d(\n        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU()\n      )\n      (branch1): Sequential(\n        (0): BasicConv2d(\n          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (1): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n        (2): BasicConv2d(\n          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU()\n        )\n      )\n      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (avgpool_1a): AdaptiveAvgPool2d(output_size=1)\n    (dropout): Dropout(p=0.6, inplace=False)\n    (last_linear): Linear(in_features=1792, out_features=512, bias=False)\n    (last_bn): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    (logits): Linear(in_features=512, out_features=8631, bias=True)\n  )\n  (arc_face): ArcFaceLoss()\n)"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"\n# --- Training Loop ---\nbest_val_auc = 0.0\nprint(\"\\n Starting Training...\")\nfor epoch in range(NUM_EPOCHS):\n    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n    val_auc = validate_one_epoch(model, val_pairs, val_is_same, eval_transform, device)\n    scheduler.step()\n\n    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Train Loss: {train_loss:.4f} | Val AUC: {val_auc:.4f} | LR: {scheduler.get_last_lr()[0]:.1e}\")\n\n    if val_auc > best_val_auc:\n        best_val_auc = val_auc\n        print(f\"New best validation AUC! Saving model to 'best_aifr_model.pth'\")\n        torch.save(model.state_dict(), 'best_aifr_model.pth')\n\nprint(\" Training finished.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":509,"referenced_widgets":["a43845be070140e180370516b2a4e817","eb5a082efbb247c4876d052e008a54bd","9410161fbbf04009a78e512b6c9c3604","de404d80730e47488ea5a3d95e1f91f9","f6010c3ced2143c39b81937124af0ac6","206f84e869c044439d984736156d481a","04f036516911426f884b242e50157246","c9e088b87f0040d8a3d3ad3d7fa553e8","dc097e2085bc4dc8bd7e19b3c0bb483f","e2be56e005854f5d9d11924bd8175b24","5cc5e52967cd4888b4d6a218834cbea6","b92d373239ee49fbb795e37c48836b15","e4173910f6a54c3296cf56dada3fc1bd","7a76d39a49964ffdac648411e909428a","9290dbd9ba8249c1819ae6fe12f7b16c","c4849a71dd61480bbc5e61db0d27309f","a6bcd567670b42a2b80e3ec6fffa23ee","b8ef492e3f9b492d93bf765011756b00","d4ce4b369eed4611b17579c4710a6a03","1d2faff9d8674be2a2482a61ce7ed43e","f22538e255f74d86adb566b93f33d448","5b529803802c420e9a95f07e28f922f0"]},"id":"gOt9PhBW8cXo","outputId":"174ba862-650c-4fd7-d471-2527dcbc5ad4","trusted":true,"execution":{"iopub.status.busy":"2025-09-12T01:21:39.371905Z","iopub.execute_input":"2025-09-12T01:21:39.372178Z","iopub.status.idle":"2025-09-12T02:37:24.759438Z","shell.execute_reply.started":"2025-09-12T01:21:39.372156Z","shell.execute_reply":"2025-09-12T02:37:24.758712Z"}},"outputs":[{"name":"stdout","text":"\n Starting Training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/390 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32894107157148d19d0ddbe7bff62357"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64cb67d5eeca414b9625560dce6bd710"}},"metadata":{}},{"name":"stdout","text":"Epoch 1/20 | Train Loss: 17.4158 | Val AUC: 0.8807 | LR: 1.0e-03\nNew best validation AUC! Saving model to 'best_aifr_model.pth'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/390 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da542d60770245b4acafcdc44da8105b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e31683512a914157a2788d4d09b00c1a"}},"metadata":{}},{"name":"stdout","text":"Epoch 2/20 | Train Loss: 12.5321 | Val AUC: 0.8997 | LR: 1.0e-03\nNew best validation AUC! Saving model to 'best_aifr_model.pth'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/390 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f4fd606de2348d1b61b17dbd29554b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d404aebda724042b89999e46d7751a9"}},"metadata":{}},{"name":"stdout","text":"Epoch 3/20 | Train Loss: 8.5285 | Val AUC: 0.8939 | LR: 1.0e-03\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/390 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43aac92d06e84071be4879a96d6c64fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab20872d5b1e4fc0b68c86374368e6f2"}},"metadata":{}},{"name":"stdout","text":"Epoch 4/20 | Train Loss: 6.3033 | Val AUC: 0.9048 | LR: 1.0e-03\nNew best validation AUC! Saving model to 'best_aifr_model.pth'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/390 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"648c1990f923418ea794d2417e7528e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b2e13a8c8254790b72d4f90c0026ca5"}},"metadata":{}},{"name":"stdout","text":"Epoch 5/20 | Train Loss: 4.9597 | Val AUC: 0.8970 | LR: 1.0e-04\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/390 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca766a132f3340cbb315104a188b3cdb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26f0b099ee884458b2ce85382de07a23"}},"metadata":{}},{"name":"stdout","text":"Epoch 6/20 | Train Loss: 3.1752 | Val AUC: 0.9109 | LR: 1.0e-04\nNew best validation AUC! Saving model to 'best_aifr_model.pth'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/390 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"288319ecf0224d44bfcd498559993f19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2853af4beb34563833c4701f088c660"}},"metadata":{}},{"name":"stdout","text":"Epoch 7/20 | Train Loss: 2.6220 | Val AUC: 0.9114 | LR: 1.0e-04\nNew best validation AUC! Saving model to 'best_aifr_model.pth'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/390 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b665910b610447088e95abbf05e3f9ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2ebf3380ea44403889566bdab0bdb38"}},"metadata":{}},{"name":"stdout","text":"Epoch 8/20 | Train Loss: 2.3265 | Val AUC: 0.9054 | LR: 1.0e-04\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/390 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acf9c9963ef340e8be205373bab75f7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1019c3c5aed4f98abe3859a7138fb3e"}},"metadata":{}},{"name":"stdout","text":"Epoch 9/20 | Train Loss: 2.0516 | Val AUC: 0.9001 | LR: 1.0e-04\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/390 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a273b712aec42aa80fc1e5093b1e2f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"263efe82774e4d66856d8a91b434ad34"}},"metadata":{}},{"name":"stdout","text":"Epoch 10/20 | Train Loss: 1.8079 | Val AUC: 0.8943 | LR: 1.0e-05\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/390 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41bed69c17ea4185ad201d335e904878"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16069329cefa49a694d6f1d223609e99"}},"metadata":{}},{"name":"stdout","text":"Epoch 11/20 | Train Loss: 1.5488 | Val AUC: 0.8939 | LR: 1.0e-05\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/390 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7eaac921faf746679c830ff079eec0e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16057df1f1404fa99c03f60a80d902a1"}},"metadata":{}},{"name":"stdout","text":"Epoch 12/20 | Train Loss: 1.5047 | Val AUC: 0.8928 | LR: 1.0e-05\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/390 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23627d3e54884d079614d5cf764c2ae8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3f4862a3f5b4381b61454dc726228db"}},"metadata":{}},{"name":"stdout","text":"Epoch 13/20 | Train Loss: 1.4667 | Val AUC: 0.8931 | LR: 1.0e-05\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/390 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb28d95009544dd6aa24c119e70366d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf33180f17c74f0bb35e1f5fc739214f"}},"metadata":{}},{"name":"stdout","text":"Epoch 14/20 | Train Loss: 1.4281 | Val AUC: 0.8899 | LR: 1.0e-05\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/390 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4806df3dd4194796a045127354554850"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eeb629126a6f4a4daf57886683fda46b"}},"metadata":{}},{"name":"stdout","text":"Epoch 15/20 | Train Loss: 1.3923 | Val AUC: 0.8896 | LR: 1.0e-06\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/390 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7f90752a0124a138ace050b7b596224"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"becf4dcda61d429f9aca89bfb08926f4"}},"metadata":{}},{"name":"stdout","text":"Epoch 16/20 | Train Loss: 1.3681 | Val AUC: 0.8892 | LR: 1.0e-06\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/390 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dce77b2469dd4f20ac5cb5f4ad81de20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"848610c5865b46c38d09535c75a2e484"}},"metadata":{}},{"name":"stdout","text":"Epoch 17/20 | Train Loss: 1.3579 | Val AUC: 0.8905 | LR: 1.0e-06\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/390 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c790637fc2a64852b47646268e53c285"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af5757360bab4c388b346cc18d743019"}},"metadata":{}},{"name":"stdout","text":"Epoch 18/20 | Train Loss: 1.3531 | Val AUC: 0.8898 | LR: 1.0e-06\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/390 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0bc66733cbc471c9bd15cf185192645"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e15b79cf2fd64d81b717f47075c75fce"}},"metadata":{}},{"name":"stdout","text":"Epoch 19/20 | Train Loss: 1.3668 | Val AUC: 0.8899 | LR: 1.0e-06\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/390 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35fff39a4f57407c8314183736930fca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44d304aae1b44a68867aa2251fd356b3"}},"metadata":{}},{"name":"stdout","text":"Epoch 20/20 | Train Loss: 1.3320 | Val AUC: 0.8890 | LR: 1.0e-07\n Training finished.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"id":"S1JHaen69-Wa"},"outputs":[],"execution_count":null}]}